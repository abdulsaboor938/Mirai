{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from neuralprophet import NeuralProphet, set_log_level\n",
    "    set_log_level(\"ERROR\")\n",
    "except:\n",
    "    !pip install neuralprophet\n",
    "    from neuralprophet import NeuralProphet, set_log_level\n",
    "    set_log_level(\"ERROR\")\n",
    "\n",
    "try:\n",
    "    import time\n",
    "except:\n",
    "    !pip install time\n",
    "    import time\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    !pip install pandas\n",
    "    import pandas as pd\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except:\n",
    "    !pip install numpy\n",
    "    import numpy as np\n",
    "    \n",
    "try:\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "except:\n",
    "    !pip install warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    import os\n",
    "except:\n",
    "    !pip install os\n",
    "    import os\n",
    "\n",
    "try:\n",
    "    import json\n",
    "except:\n",
    "    !pip install json\n",
    "    import json\n",
    "\n",
    "### function starts here\n",
    "def training(zone,temp):\n",
    "    \n",
    "    df = temp.copy()\n",
    "    df = df[df['zone'] == zone]\n",
    "\n",
    "    df['ds'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # get the last date\n",
    "    last_date = df['ds'].max()\n",
    "    # print(last_date)\n",
    "\n",
    "    # convert this date to epoch\n",
    "    last_date_epoch = (last_date.value // 10**9) + 3600\n",
    "    # print(last_date_epoch)\n",
    "\n",
    "    # get current epoch\n",
    "    import time\n",
    "    current_epoch = int(time.time())\n",
    "    # print(current_epoch)\n",
    "\n",
    "    # add 7 days to current epoch\n",
    "    future_epoch = current_epoch + 7 * 24 * 60 * 60\n",
    "    # print(future_epoch)\n",
    "\n",
    "    df_future = pd.DataFrame(np.arange(last_date_epoch, future_epoch, 60 * 60), columns=['timestamp'])\n",
    "    df_future['ds'] = pd.to_datetime(df_future['timestamp'], unit='s')\n",
    "    df_future.drop(['timestamp'], axis=1, inplace=True)\n",
    "    df_future.head()\n",
    "    df_future['zone'] = df['zone'].iloc[0]\n",
    "    df_future['longitude'] = df['longitude'].iloc[0]\n",
    "    df_future['latitude'] = df['latitude'].iloc[0]\n",
    "    df_future.head()\n",
    "\n",
    "\n",
    "    ### Temperature\n",
    "    training_data = df[['ds']]\n",
    "    training_data['y'] = df['temperature']\n",
    "    training_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # predicitng temperature by multiplicative model\n",
    "    from neuralprophet import NeuralProphet, set_log_level, df_utils\n",
    "    set_log_level(\"ERROR\")\n",
    "    m = NeuralProphet(\n",
    "        changepoints_range=0.95,\n",
    "        n_changepoints=24,\n",
    "        trend_reg=1,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=1,\n",
    "        seasonality_mode=\"multiplicative\",\n",
    "    )\n",
    "    m.set_plotting_backend(\"matplotlib\")\n",
    "    metrics = m.fit(training_data, freq=\"60min\")\n",
    "    future = m.make_future_dataframe(training_data, periods=len(df_future), n_historic_predictions=True)\n",
    "    forecast = m.predict(future)\n",
    "    df_future['temperature'] = forecast.tail(len(df_future))['yhat1'].values\n",
    "    print('temperature done')\n",
    "\n",
    "\n",
    "    ### PM2_5\n",
    "    training_data = df[['ds']]\n",
    "    training_data['y'] = df['pm2_5']\n",
    "    training_data.reset_index(inplace=True, drop=True)\n",
    "    # predicitng temperature by multiplicative model\n",
    "    m = NeuralProphet(\n",
    "        changepoints_range=0.95,\n",
    "        n_changepoints=24,\n",
    "        trend_reg=1,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=1,\n",
    "        seasonality_mode=\"multiplicative\",\n",
    "    )\n",
    "    m.set_plotting_backend(\"matplotlib\")\n",
    "    metrics = m.fit(training_data, freq=\"60min\")\n",
    "    future = m.make_future_dataframe(training_data, periods=len(df_future), n_historic_predictions=True)\n",
    "    forecast = m.predict(future)\n",
    "    df_future['pm2_5'] = forecast.tail(len(df_future))['yhat1'].values\n",
    "    print('pm2_5 done')\n",
    "\n",
    "\n",
    "    ### PM10\n",
    "    training_data = df[['ds']]\n",
    "    training_data['y'] = df['pm10']\n",
    "    training_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # predicitng temperature by multiplicative model\n",
    "    m = NeuralProphet(\n",
    "        changepoints_range=0.95,\n",
    "        n_changepoints=24,\n",
    "        trend_reg=1,\n",
    "        weekly_seasonality=False,\n",
    "        daily_seasonality=1,\n",
    "        seasonality_mode=\"multiplicative\",\n",
    "    )\n",
    "    m.set_plotting_backend(\"matplotlib\")\n",
    "    metrics = m.fit(training_data, freq=\"60min\")\n",
    "    future = m.make_future_dataframe(training_data, periods=len(df_future), n_historic_predictions=True)\n",
    "    forecast = m.predict(future)\n",
    "    df_future['pm10'] = forecast.tail(len(df_future))['yhat1'].values\n",
    "    print('pm10 done')\n",
    "\n",
    "\n",
    "    df_future['smog'] = np.where((df_future['temperature'] < 25) & (df_future['pm10'] > 300), df_future[['pm10', 'pm2_5']].max(axis=1), np.nan)\n",
    "    df_future['ds'] = pd.to_datetime(df_future['ds']).dt.strftime('%B %d, %Y, %I:%M %p')\n",
    "    df_future.columns = ['date', 'zone', 'longitude', 'latitude', 'temperature', 'pm2_5', 'pm10', 'smog']\n",
    "\n",
    "\n",
    "    # create directory if not exists\n",
    "    if not os.path.exists('prediction'):\n",
    "        os.makedirs('prediction')\n",
    "    df_future.to_csv(f'prediction/{zone}.csv', index=False)\n",
    "    \n",
    "    print(f'{zone} done!!')\n",
    "    print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7063ff9cac8b4af38aa5a35296b16b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab14e8495af49488fac0c8394f2e8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350943d5bab34f998ba1eb0cc0e496dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 317it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a100b4e4fd431faa2cc448c172211e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd3ab676fd84ac582394ba78ca997ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884c738dd7604197b31447dc25c8bd55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 317it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pm2_5 done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0c7b09473545e3ac64fbac05583541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/257 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad67c26acceb46e89b3d3c84960c79e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6c37a721054fcbad3f8d5eb6c5cb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 317it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# delete the json file\n",
    "if os.path.exists('checkpoints.json'):\n",
    "    os.remove('checkpoints.json')\n",
    "for i in range(60,70):\n",
    "    training(i,temp) # training function\n",
    "    # append checkpoints to a json file, if the file does not exist, create it\n",
    "    if not os.path.exists('checkpoints.json'):\n",
    "        with open('checkpoints.json', 'w') as f:\n",
    "            json.dump([], f)\n",
    "    # read the json file\n",
    "    with open('checkpoints.json', 'r') as f:\n",
    "        checkpoints = json.load(f)\n",
    "    # append the checkpoint\n",
    "    checkpoints.append(i)\n",
    "    # write the json file\n",
    "    with open('checkpoints.json', 'w') as f:\n",
    "        json.dump(checkpoints, f)\n",
    "    # write value of i to checkpoints.txt\n",
    "    with open('checkpoints.txt', 'w') as f:\n",
    "        f.write(str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
